{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import gc\n",
    "import os\n",
    "import math\n",
    "import functools\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from six.moves import xrange \n",
    "\n",
    "\n",
    "log = logging.getLogger('log')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "lhnd = logging.StreamHandler()\n",
    "lhnd.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "lhnd.setFormatter(formatter)\n",
    "\n",
    "log.addHandler(lhnd)\n",
    "\n",
    "%autonotify -a 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmap(f, arr):\n",
    "    return list(map(f, arr))\n",
    "\n",
    "def lfilter(f, arr):\n",
    "    return list(filter(f, arr))\n",
    "\n",
    "def foreach(it, f):\n",
    "    for e in it:\n",
    "        f(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('auth/token') as f:\n",
    "    token = f.readline().strip()\n",
    "    \n",
    "\n",
    "\n",
    "def get_info(ids):\n",
    "    mc = 'members_count'\n",
    "    payload = {'v': '5.92', 'access_token': token, 'fields':mc}\n",
    "    \n",
    "    str_ids = functools.reduce(\n",
    "        lambda x, y: x + y,\n",
    "        lmap(lambda x: str(x) + ',', ids)\n",
    "    )\n",
    "    \n",
    "    payload['group_ids'] = str_ids[0:- 1]\n",
    "    \n",
    "    r = requests.get('https://api.vk.com/method/groups.getById', \n",
    "                     params=payload)\n",
    "    res = lmap(lambda x: (x['name'], x['screen_name'], x[mc] if mc in x else -1),r.json()['response'])\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 947528\n",
    "\n",
    "def raw_data_filter(file):\n",
    "    # Mapping to events\n",
    "    res = list()\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    for line in file:\n",
    "        cur = line.rstrip().split(',')\n",
    "        cur = lmap(lambda p: (re.sub(';.*', '', p), re.sub('.*;', '', p)), cur)\n",
    "\n",
    "        session = list()\n",
    "        \n",
    "        for j in range(0, len(cur)):\n",
    "            try:\n",
    "                session.append(int(cur[j][1]))\n",
    "            except ValueError:\n",
    "                None\n",
    "                \n",
    "        res.append(session)\n",
    "\n",
    "        i = i + 1\n",
    "                \n",
    "        if (i % 100000 == 0):\n",
    "            gc.collect()\n",
    "\n",
    "            log.debug(\"%d %% of mapping is done.\", i / total * 100)\n",
    "\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data_filter(open(\"data/sessions_public.txt\",\"r\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_count(data):\n",
    "    total = dict()\n",
    "\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            if (j in total.keys()):\n",
    "                total[j] = total[j] + 1\n",
    "            else:\n",
    "                total[j] = 1\n",
    "                \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_map(lst, cnt, min_allowed, min_session_size):\n",
    "    result = []\n",
    "    groups = set()\n",
    "    \n",
    "    for session in lst:\n",
    "        unsub = set()\n",
    "        sub = set()\n",
    "        \n",
    "        for event in session:\n",
    "            if (event < 0):\n",
    "                sub_event = -event\n",
    "                \n",
    "                if (sub_event in sub):\n",
    "                    sub.remove(sub_event)\n",
    "                    \n",
    "                unsub.add(sub_event)\n",
    "            else:\n",
    "                if (not event in unsub):\n",
    "                    if (cnt == None or cnt[event] > min_allowed):\n",
    "                        sub.add(event)\n",
    "        \n",
    "        if (len(sub) >= min_session_size):\n",
    "            for event in sub:\n",
    "                groups.add(event)\n",
    "            \n",
    "            result.append(sub)\n",
    "    \n",
    "    return result, groups\n",
    "\n",
    "def drop_uncommon(raw_data, min_allowed = 10, min_session_size = 4):\n",
    "    cnt = None\n",
    "    sorted_cnt = None\n",
    "    \n",
    "    data = raw_data\n",
    "    groups = None\n",
    "    \n",
    "    while (cnt == None or sorted_cnt[0] < min_allowed):\n",
    "        data, groups = set_map(data, cnt, min_allowed, min_session_size)\n",
    "        \n",
    "        cnt = group_count(data) \n",
    "        sorted_cnt = sorted(list(cnt.values()))\n",
    "        \n",
    "        log.info(\"Length of data:   %d\", len(data))\n",
    "        log.info(\"Total length:     %d\", \n",
    "                functools.reduce((lambda x, y: x + y), lmap(lambda a: len(a), data))\n",
    "                )\n",
    "        log.info(\"Number of groups: %d\", len(groups))\n",
    "        log.info(\"Minimum count:    %d\", sorted_cnt[0])\n",
    "        \n",
    "    return data, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = drop_uncommon(data)\n",
    "data, groups = drop_uncommon(raw_data, 10)\n",
    "\n",
    "most_common = sorted(group_count(data).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "w2i = {w: i for i, w in enumerate(groups)}\n",
    "i2w = {i: w for i, w in enumerate(groups)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dex = 0\n",
    "event_dex = 0\n",
    "\n",
    "def generate_batch(batch_size):\n",
    "    global session_dex\n",
    "    global event_dex\n",
    "    \n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    \n",
    "    current = 0\n",
    "    session = list(data[session_dex])\n",
    "    \n",
    "    while (current * 2 < batch_size):\n",
    "        batch[current * 2] = w2i[session[event_dex + 1]]\n",
    "        labels[current * 2][0] = w2i[session[event_dex]]\n",
    "        batch[current * 2 + 1] = w2i[session[event_dex + 1]]\n",
    "        labels[current * 2 + 1][0] = w2i[session[(event_dex + 2) % len(session)]]\n",
    "        \n",
    "        event_dex += 1\n",
    "        current += 1\n",
    "        \n",
    "        if (event_dex + 2 >= len(session)):\n",
    "            event_dex = 0\n",
    "            session_dex = session_dex + 1\n",
    "            if (session_dex >= len(data)):\n",
    "                session_dex = 0\n",
    "            session = list(data[session_dex])\n",
    "\n",
    "     \n",
    "    return batch, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch, labels = generate_batch(10)\n",
    "\n",
    "print(data[0])\n",
    "print(data[1])\n",
    "\n",
    "for i in range(10):\n",
    "    print(batch[i], i2w[batch[i]], '->', labels[i, 0],\n",
    "          i2w[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128\n",
    "num_sampled = 64\n",
    "vocabulary_size = len(groups)\n",
    "\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Input data.\n",
    "    with tf.name_scope('inputs'):\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "    # Ops and variables pinned to the CPU because of missing GPU implementation\n",
    "    with tf.device('/cpu:0'):\n",
    "        # Look up embeddings for inputs.\n",
    "        with tf.name_scope('embeddings'):\n",
    "            embeddings = tf.Variable(\n",
    "                tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)\n",
    "            )\n",
    "            embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "      # Construct the variables for the NCE loss\n",
    "    with tf.name_scope('weights'):\n",
    "        nce_weights = tf.Variable(\n",
    "            tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    with tf.name_scope('biases'):\n",
    "        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Compute the average NCE loss for the batch.\n",
    "    # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "    # time we evaluate the loss.\n",
    "    # Explanation of the meaning of NCE loss:\n",
    "    #   http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(\n",
    "                  weights=nce_weights,\n",
    "                  biases=nce_biases,\n",
    "                  labels=train_labels,\n",
    "                  inputs=embed,\n",
    "                  num_sampled=num_sampled,\n",
    "                  num_classes=vocabulary_size))\n",
    "        \n",
    "        # Add the loss value as a scalar to summary.\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "    with tf.name_scope('optimizer'):\n",
    "          optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "\n",
    "    # Compute the cosine similarity between minibatch examples and all\n",
    "    # embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    #valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,\n",
    "    #                                          valid_dataset)\n",
    "    #similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "    # Merge all summaries.\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(emb, index):\n",
    "    p = emb[index]\n",
    "    cnst = tf.constant(p, shape=[1, embedding_size])\n",
    "    d = tf.matmul(cnst, emb, transpose_b=True).eval()[0]\n",
    "\n",
    "    dxs = np.argsort(np.array(d))\n",
    "\n",
    "    ids = []\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(dxs) - 10, len(dxs)):\n",
    "        ids.append(i2w[dxs[i]])\n",
    "        res.append(d[dxs[i]])\n",
    "        \n",
    "    info = get_info(ids)\n",
    "    \n",
    "    for i in xrange(len(res)):\n",
    "        print(ids[i], ' ', res[i], ' ', info[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_steps = 337960\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # Open a writer to write summaries.\n",
    "    writer = tf.summary.FileWriter(\"tmp\", session.graph)\n",
    "\n",
    "    # We must initialize all variables before we use them.\n",
    "    init.run()\n",
    "    print('Initialized')\n",
    "\n",
    "    average_loss = 0\n",
    "    for step in xrange(num_steps):\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size)\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "\n",
    "        # Define metadata variable.\n",
    "        run_metadata = tf.RunMetadata()\n",
    "\n",
    "        # We perform one update step by evaluating the optimizer op (including it\n",
    "        # in the list of returned values for session.run()\n",
    "        # Also, evaluate the merged op to get all summaries from the returned\n",
    "        # \"summary\" variable. Feed metadata variable to session for visualizing\n",
    "        # the graph in TensorBoard.\n",
    "        _, summary, loss_val = session.run([optimizer, merged, loss],\n",
    "                                         feed_dict=feed_dict,\n",
    "                                         run_metadata=run_metadata)\n",
    "        average_loss += loss_val\n",
    "\n",
    "        # Add returned summaries to writer in each step.\n",
    "        writer.add_summary(summary, step)\n",
    "        # Add metadata to visualize the graph for the last run.\n",
    "        if step == (num_steps - 1):\n",
    "            writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                  average_loss /= 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000\n",
    "            # batches.\n",
    "            print('Average loss at step ', step, ': ', average_loss)\n",
    "            average_loss = 0\n",
    "            \n",
    "        if step % 20000 == 0 and step != 0:\n",
    "            print('Most closest to ', most_common[0][0])\n",
    "            get_closest(normalized_embeddings.eval(), w2i[most_common[0][0]])\n",
    "            \n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150388347   0.576734   ('Модные Прически', 'modnue.pricheski', 1381005)\n",
      "151779453   0.57750046   ('Я никогда не...', 'never_did', 691581)\n",
      "73776762   0.5840418   ('Восемнадцать плюс', 'vosplus', 2003817)\n",
      "71474813   0.5844791   ('Реальный Футбол | Битва поколений', 'refoot', 2531028)\n",
      "28293246   0.59798276   ('Just love', 'vk.just.love', 3906799)\n",
      "22741624   0.6135372   ('Улетные приколы', 'humour.page', 5214000)\n",
      "30532220   0.61808896   ('СМС приколы :D', 'i4sms', 3272684)\n",
      "29573241   0.6675201   ('NR', 'rapnewrap', 4741209)\n",
      "26147450   0.6954052   ('Школа? Не, не слышали', 'onesc', 3863075)\n",
      "27895931   0.9999999   ('Новинки Музыки 2019 | Новая Музыка', 'exclusive_muzic', 16384210)\n",
      "\n",
      "\n",
      "23758942   0.5705687   ('Взрослей', 'pafos_oo', 2999892)\n",
      "105999460   0.57192314   ('Мои аудиозаписи', 'my_audios', 2622243)\n",
      "31613023   0.576375   ('Чёртов стыд', 'grebaniy_stid', 1598456)\n",
      "149537884   0.59037364   ('Смотри что Я сделяль!', 'sdelyall', 1219087)\n",
      "116779618   0.5985114   ('Кактус Коля', 'kaktuskola', 314894)\n",
      "72378974   0.61667365   ('Мой Компьютер', 'myironcomp', 1196334)\n",
      "73831523   0.6581749   ('Live In Tattoo | Татуировки', 'liveintattoo', 1091424)\n",
      "148059228   0.6589261   ('СигнаL', 'signaphoto', 3020408)\n",
      "132239455   0.6664603   ('Смотри, что я купил', 'club132239455', 1188218)\n",
      "45441631   0.9999999   ('ПРИКОЛЫ | Смеяка', 'smeyaka', 10902737)\n",
      "\n",
      "\n",
      "50138149   0.5907766   ('Реальность.', 'is.the.reality', 2078510)\n",
      "88469025   0.5925573   ('БУДЬ В КУРСЕ (БВК)', 'v_kyrce', 673410)\n",
      "6246566   0.5927892   ('МУЗ-ТВ', 'muztv', 1829586)\n",
      "35061290   0.5966829   ('Эгоист', 'e_goist', 4747523)\n",
      "94255146   0.61293805   ('Реально смешно', 'onovoe', 1995266)\n",
      "24199209   0.6148579   ('LIFE | Новости', 'life', 1996380)\n",
      "77093415   0.6411072   ('Лайфхакум | Советы, хитрости, идеи', 'vk_lifehack_club', 1272951)\n",
      "133668394   0.67619145   ('Заброшенное', 'zabroshenoevk', 3104676)\n",
      "39153701   0.6911856   ('Злой Гений', 'evill_genius', 3492917)\n",
      "26419239   0.9999999   ('Смейся до слёз :D', 'ifun', 11159769)\n",
      "\n",
      "\n",
      "42144182   0.5722703   ('skromno', 'skromno_vk', 971461)\n",
      "56918454   0.5839436   ('Читающие', 'club56918454', 1125041)\n",
      "36166073   0.5988996   ('Ты на понтах, я на каблуках.©', 'on.heels', 3726014)\n",
      "149094324   0.6040858   ('Комментатор от Бога', 'komment.broo', 1698405)\n",
      "133814709   0.61621344   ('Замедленная съемка | Gif', 'slowmovies', 998154)\n",
      "78622646   0.6266579   ('Интересно знать | Наука и факты', 'welsis', 1550580)\n",
      "38683579   0.6438988   ('Лучшие стихи великих поэтов | Литература', '1poetry', 6083867)\n",
      "22798006   0.6460554   ('Киномания', 'kino_mania', 11431397)\n",
      "32370614   0.70771194   ('MARVEL/DC', 'marvel_dc', 3431920)\n",
      "58170807   0.99999976   ('КиноКайф - Лучшие фильмы', 'kino_kaif', 9605785)\n",
      "\n",
      "\n",
      "45703770   0.57191145   ('Музыка', 'vkmuz', 4983581)\n",
      "46105176   0.57324123   ('Новинки кино ★ Т-34 | Полицейский с Рублёвки', 'new_kino_o', 1882101)\n",
      "94302419   0.5809232   ('Гифач | Гифки', 'gifki', 908833)\n",
      "126100310   0.58235055   ('Маникюр | Ногти | Педикюр | Идеи 2019', 'women.nails', 3285198)\n",
      "67580761   0.58700746   ('КБ', 'countryballs_re', 1257792)\n",
      "26492122   0.604583   ('EA7', 'emporioarmani_7', 1482781)\n",
      "127090395   0.64260066   ('Иллюзионист', 'illusionistvk', 2024171)\n",
      "45608667   0.64982516   ('Шутник', 'shutniki_ru', 4357221)\n",
      "43776215   0.787217   ('Я тебя хочу', 'iwantyou', 6195565)\n",
      "43215063   1.0   ('Киномания | Новинки 2019', 'kinomania', 12208659)\n",
      "\n",
      "\n",
      "156882121   0.59878755   ('Смекалочка | GIF', 'xalife', 669105)\n",
      "119377097   0.6002635   ('A L O N E', 'alonelys', 1225493)\n",
      "22522055   0.6024964   ('Сбербанк', 'sberbank', 2569098)\n",
      "22753480   0.61097145   ('Discovery', 'tweas', 1705513)\n",
      "77843142   0.61453784   ('Не беси', 'ne6esi', 2011261)\n",
      "80044744   0.61858463   ('Твой любимый сериал  | SKAM / РИВЕРДЕЙЛ', 'lubimiy.serial', 1012009)\n",
      "145510087   0.6437865   ('ИДЕАЛЬНО', 'superidealno', 1556578)\n",
      "86218441   0.6555147   ('Психология', 'psy_real', 3250460)\n",
      "26030283   0.670519   ('Сарказм', 'agil_vk', 4535418)\n",
      "91050183   0.99999994   ('Леонардо Дай Винчик', 'dayvinchik', 7289940)\n",
      "\n",
      "\n",
      "155590170   0.5505915   ('ОРУ, СЭР!', 'medieval_or', 2167103)\n",
      "30823579   0.5819628   ('ФИЛЬМЫ УЖАСОВ', 'nightmares', 1744274)\n",
      "151229592   0.58313334   ('НЕтипичные факты', 'nfacty', 1395211)\n",
      "144962203   0.58742154   ('И так сойдет!', 'itaksodet', 1241885)\n",
      "64977560   0.59500724   ('EA7 | MUSIC |', 'e_a_7_music', 1880191)\n",
      "139740824   0.6002177   ('Бот Лена', 'bot_lena', 1395500)\n",
      "23390361   0.62155294   ('Это интересно!', 'smart_log', 3908742)\n",
      "34215577   0.626065   ('Подслушано', 'overhear', 3946857)\n",
      "120254617   0.6376679   ('$$$ DANK MEMES $$$ AYY LMAO $$$', 'dank_memes_ayylmao', 580395)\n",
      "57846937   0.99999994   ('MDK', 'mudakoff', 10483339)\n",
      "\n",
      "\n",
      "18496184   0.5883862   ('СТС', 'ctc', 3115223)\n",
      "152435896   0.6066171   ('ТРЭШ', 'club152435896', 1301996)\n",
      "54500021   0.6082889   ('Новинки Музыки 2019', 'exclusive_songs', 1439433)\n",
      "26062647   0.6192814   ('Kate Mobile', 'kate_mobile', 5897323)\n",
      "34378420   0.64601034   ('Не мы такие  - жизнь такая', 'mytk1es', 2564987)\n",
      "58170807   0.6460554   ('КиноКайф - Лучшие фильмы', 'kino_kaif', 9605785)\n",
      "32370614   0.6835736   ('MARVEL/DC', 'marvel_dc', 3431920)\n",
      "45745333   0.6838178   ('4ch', '4ch', 4962912)\n",
      "23213239   0.6971351   ('Дзен', 'dzenpub', 2818905)\n",
      "22798006   1.0000001   ('Киномания', 'kino_mania', 11431397)\n",
      "\n",
      "\n",
      "108477741   0.5709563   ('Элитный Юмор', 'toxic_humor', 1434030)\n",
      "68895020   0.5745063   ('КТО сверху', 'ktosverxy', 4033326)\n",
      "128338223   0.5967833   ('Давай, удивляй', 'davai_udivi', 893288)\n",
      "149925677   0.6037697   ('Say.', 'club149925677', 1099076)\n",
      "122282289   0.6180465   ('ты сохранишь.', 'forver2016', 437874)\n",
      "12353330   0.64057094   ('На Случай Важных Переговоров', 'peregovorov', 2786659)\n",
      "35809584   0.65562797   ('Hi-Tech | Наука и техника', 'tech.science', 1832135)\n",
      "48512305   0.678752   ('Телеканал ТНТ', 'tnt', 4876396)\n",
      "66678575   0.7100995   ('Овсянка, сэр!', 'ovsyanochan', 4145209)\n",
      "135209264   1.0   ('Бот Максим', 'bot_maxim', 5097534)\n",
      "\n",
      "\n",
      "95128240   0.5976789   ('Смертельный юмор', 'smehizhizn', 1740251)\n",
      "151257260   0.5987773   ('Осмысленное', 'osmyslennoe', 1028744)\n",
      "65047210   0.6011939   ('Гифки :3', 'fun.gifs', 1849423)\n",
      "144853678   0.6042826   ('ТЫЖЕДЕВОЧКА', 'tigede', 951561)\n",
      "23308460   0.6069876   ('theend.', 'the1end', 2843694)\n",
      "78388911   0.63748956   ('Книга рекордов', 'book.record', 3874615)\n",
      "149126828   0.6406744   ('Филиал сообщений от родственников', 'momsms', 1839144)\n",
      "49603755   0.68117356   ('случайность', 'usatm', 2499794)\n",
      "46509740   0.7223425   ('Маникюр | Ногти', 'modnailru', 3682328)\n",
      "23064236   1.0   ('Четкие Приколы', 'ilikes', 8581328)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        get_closest(final_embeddings, w2i[most_common[i][0]])\n",
    "        \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80701061   0.43979344   ('Apple Барахолка Саратов', 'applebarahlo64', 7344)\n",
      "46007784   0.44030026   ('YouTube Angelville', 'yt_angelville', 23418)\n",
      "43686317   0.4434111   ('Работа Вакансии Работодатели в Калининграде', 'jobs39', 90756)\n",
      "63303836   0.44487107   ('kipish', 'kipish088', 244231)\n",
      "152366773   0.44687134   ('Рыбалка с AliExpress', 'club152366773', 4800)\n",
      "109496640   0.45852435   ('Барахолка Псков', 'club109496640', 12758)\n",
      "102268559   0.46084452   ('7NN 🌴', '7noname', 39879)\n",
      "135339893   0.4645276   ('CrockidUfa (КрокидУфа) Детская одежда в Уфе', 'crockidufa', 5438)\n",
      "71458926   0.50234413   ('Бронницы 24', 'bron24', 8847)\n",
      "8780658   1.0000001   ('Кубик Рубика. Спидкубинг (официальная группа)', 'ruspeedcubing', 45648)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    get_closest(final_embeddings, len(groups) // 4 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
